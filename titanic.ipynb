{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import appropriate packages and set analysis options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot') \n",
    "#from sklearn import linear_model, preprocessing\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "#from sklearn.model_selection import cross_val_score, train_test_split\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#from math import sqrt\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from scipy import stats\n",
    "\n",
    "# Setting save_predicted_data to True\n",
    "# will cause the notebook to save data\n",
    "# in one of the last notebook cells.\n",
    "# The data will be saved to the path\n",
    "# specified by MY_PREDICTED_DATA_PATH.\n",
    "save_predicted_data = False\n",
    "\n",
    "# As expected, setting print_all_output\n",
    "# to True will cause each evaluation in a\n",
    "# a cell to be displayed. This has the\n",
    "# unfortunate side-effect of preventing the\n",
    "# ';' operator from silencing output.\n",
    "# If this boolean is set to False, then\n",
    "# only the last item in each cell may\n",
    "# be output.\n",
    "print_all_output = False\n",
    "InteractiveShell.ast_node_interactivity = 'all' if print_all_output else 'last_expr'\n",
    "\n",
    "# Setting engineer_features to True will\n",
    "# enable the creation of new data/features\n",
    "# from the original data. This makes it\n",
    "# simpler to include/exclude this extra\n",
    "# data and determine whether it helps\n",
    "# improve the models.\n",
    "# WARNING: if set to True, then these same\n",
    "# engineered features must be provided/added\n",
    "# to the test data so that the prediction model\n",
    "# has the same number of input features for both\n",
    "# the training and testing data.\n",
    "engineer_features = False\n",
    "\n",
    "# Setting one_hot_encoding to True will cause\n",
    "# categorical features not only to be encoded\n",
    "# but to be one-hot encoded. This transforms\n",
    "# all categorical labels into individual\n",
    "# columns to prevent spurious effects related\n",
    "# to sequential int encodings.\n",
    "# WARNING: if set to True, the training and test\n",
    "# data will be encoded with a different number of\n",
    "# categorical labels / columns, so the training\n",
    "# model would not be applicable to the test data.\n",
    "# Currently, this notebook does not support\n",
    "# one-hot encoding both the training and testing\n",
    "# data sets.\n",
    "one_hot_encoding = False\n",
    "\n",
    "# Setting randomize_seeding to True will\n",
    "# randomize various operations throughout\n",
    "# the notebook. Setting it to False will\n",
    "# cause the seed to remain fixed to some\n",
    "# specified value such that the notebook\n",
    "# can be reran with the same randomized\n",
    "# variables (see MAGIC_SEED below).\n",
    "randomize_seeding = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define convenient variables and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These paths indicate from where the training,\n",
    "# test, and prediction data will be loaded/saved.\n",
    "TRAINING_DATA_PATH = \"./data/train.csv\"\n",
    "TEST_DATA_PATH = \"./data/test.csv\"\n",
    "MY_PREDICTED_DATA_PATH = \"./data/my_predicted_survivors.csv\"\n",
    "\n",
    "# The MAGIC_SEED optionally specifies a fixed\n",
    "# random state/seed so that the notebook can be\n",
    "# reran with the same randomized variables (see\n",
    "# randomize_seeding above).\n",
    "MAGIC_SEED = 1776\n",
    "if (randomize_seeding):\n",
    "    MAGIC_SEED = np.random.seed()\n",
    "\n",
    "# The training data provided with this data\n",
    "# set will be split into two subsets so that\n",
    "# models can be trained on the first and tested\n",
    "# on the second. TRAINING_DATA_TEST_SIZE\n",
    "# indicates the proportion of the training\n",
    "# data that will be used as test data for\n",
    "# model evaluation and should be in the\n",
    "# range [0.0, 1.0].\n",
    "TRAINING_DATA_TEST_SIZE = 0.10\n",
    "\n",
    "def load_data(path, index_column):\n",
    "    \"\"\"\n",
    "    Load the file at 'path' into a Pandas\n",
    "    DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, header=0, index_col=index_column)\n",
    "    print(\"Loaded data dimensions: \", df.shape[0], \"rows, \", df.shape[1], \"columns\")\n",
    "    return df\n",
    "\n",
    "def print_nan(nan_cols_counts, col_type):\n",
    "    \"\"\"\n",
    "    Print each element of the list which should contain\n",
    "    a DataFrame feature name and an int number of times\n",
    "    the feature contains an NaN value.\n",
    "    \"\"\"\n",
    "    print(\"\\n\", len(nan_cols_counts), \" \", col_type, \"-type columns with NaN values.\", sep='')\n",
    "    if(len(nan_cols_counts) > 0):\n",
    "        print(\"    {:<16}{}\".format(\"Feature\", \"NaN Count\"))\n",
    "        print(\"%s\" % \"    ---------------------\")\n",
    "    for index, element in enumerate(nan_cols_counts):\n",
    "        print(\"{:>2}. {:<16}{}\".format(index+1, element[0], element[1]))\n",
    "        \n",
    "def gather_nan(df, col_type, print_if_nan = True):\n",
    "    \"\"\"\n",
    "    Find all DataFrame columns of type 'col_type'\n",
    "    which contain NaN values.\n",
    "    \"\"\"\n",
    "    if (col_type == \"int\"):\n",
    "        columns = df.select_dtypes(include=['int']).columns\n",
    "    elif (col_type == \"float\"):\n",
    "        columns = df.select_dtypes(include=['float']).columns\n",
    "    else:\n",
    "        columns = df.select_dtypes(include=['object']).columns\n",
    "    nan_cols_counts = []\n",
    "    for col in np.sort(columns):\n",
    "        num_nan = np.sum(df[col].isnull())\n",
    "        if (num_nan > 0):\n",
    "            nan_cols_counts.append((col, num_nan))\n",
    "    if (print_nan):\n",
    "        print_nan(nan_cols_counts, col_type)\n",
    "    return nan_cols_counts\n",
    "            \n",
    "def replace_with_normal(df, col, seed = np.random.seed()):\n",
    "    \"\"\"\n",
    "    Replace NaN values in a DataFrame column with\n",
    "    values chosen from a normal distribution with\n",
    "    a mean and standard deviation equal to the\n",
    "    that of the non-NaN data.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    df_dropped = df[col].dropna()\n",
    "    mu = np.mean(df_dropped)\n",
    "    sigma = np.std(df_dropped)\n",
    "    null_rows = df[col].isnull()\n",
    "    num_nan = np.sum(null_rows)\n",
    "    rand_vals = np.random.normal(mu, sigma, num_nan)\n",
    "    df.loc[null_rows, col] = rand_vals\n",
    "    \n",
    "def most_common_label(df, col):\n",
    "    \"\"\"\n",
    "    Determine the most fequent label for\n",
    "    categorical data.\n",
    "    \"\"\"\n",
    "    most_common_appearances = 0\n",
    "    most_common_label = \"\"\n",
    "    for label in df[col].unique():\n",
    "        num_appearances = np.sum(df[col] == label)\n",
    "        if (num_appearances > most_common_appearances):\n",
    "            most_common_appearances = num_appearances\n",
    "            most_common_label = label\n",
    "    return most_common_label\n",
    "\n",
    "def evaluate_model(x_train, y_train, model):\n",
    "    \"\"\"\n",
    "    Given an input model and training data,\n",
    "    split the data into training/testing subsets\n",
    "    and use this to produce a fit and predictions.\n",
    "    Indicate the goodness of the fit and plot\n",
    "    the results.\n",
    "    \"\"\"\n",
    "    # Split the training data into two subsets.\n",
    "    # Then, train the model on the target data\n",
    "    # and use it to predict home prices.\n",
    "    x_train1, x_train2, y_train1, y_train2 = train_test_split(\n",
    "        x_train, y_train,\n",
    "        test_size=TRAINING_DATA_TEST_SIZE,\n",
    "        random_state=MAGIC_SEED)\n",
    "    model.fit(x_train1, y_train1)\n",
    "    y_train2_pred = model.predict(x_train2)\n",
    "    \n",
    "    # Evaluate the model & predictions by viewing\n",
    "    # the cross-validation score, error, and\n",
    "    # variance (where a variance of 1 indicates\n",
    "    # a perfect prediction) and plotting the results.\n",
    "    print(cross_val_score(model, x_train1, y_train1, cv=5))\n",
    "    print(\"RMS Error: %.3f\"\n",
    "        % sqrt(mean_squared_error(y_train2, y_train2_pred)))\n",
    "    print('Variance score: %.3f' % r2_score(y_train2, y_train2_pred))\n",
    "    plt.scatter(y_train2, y_train2_pred, color='red', marker='x')\n",
    "    plt.scatter(y_train2, y_train2, color='black', marker='.')\n",
    "    plt.xlabel(\"True House Price\")\n",
    "    plt.ylabel(\"House Price\")\n",
    "    plt.legend((\"Predicted Value\", \"True Value\"))\n",
    "    plt.show()\n",
    "    \n",
    "def most_important_features(df, feature_importances, num_features):\n",
    "    \"\"\"\n",
    "    Select and pritn out the N most important features used\n",
    "    in the model to make predictions.\n",
    "    \"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    sorted_indices = np.argsort(importances)[::-1].tolist()\n",
    "    top_n_indices = sorted_indices[:5]\n",
    "    print(\"The %d most important features for this model:\" % num_features)\n",
    "    for ii, index in enumerate(top_n_indices):\n",
    "        print(\"%d. %s\" % (ii+1, df.columns[index]))\n",
    "\n",
    "def encode(df):\n",
    "    \"\"\"\n",
    "    Convert categorical labels to ints.\n",
    "    \"\"\"\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    encoded_label_groups = []\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        label_encoder.fit(df[col].unique());\n",
    "        encoded_label_groups.append(label_encoder.classes_.tolist())\n",
    "        df.loc[:, col] = label_encoder.transform(df[col]);\n",
    "    return encoded_label_groups\n",
    "\n",
    "# The following function was originally written for debugging\n",
    "# purposes but was retained in case it was useful in the future.\n",
    "# For an arbitrary feature index, the function prints details\n",
    "# about that particular feature's encoding and shows that the\n",
    "# one_hot_cols columns properly partition/encode the int values\n",
    "# in the feature's column.\n",
    "def test_one_hot_encoding(df, features_and_encoded_labels, one_hot_cols, feature_index):\n",
    "    \"\"\"\n",
    "    Print a few elements of an encoded column and compare\n",
    "    the data to the one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    categorical_features = [pair[0] for pair in features_and_encoded_labels]\n",
    "    encoded_label_groups = [label for pair in features_and_encoded_labels for label in pair[1]]\n",
    "    feature = categorical_features[feature_index]\n",
    "    label_group_starting_index = sum(len(labels) for labels in encoded_label_groups[0:feature_index])\n",
    "    num_group_labels = len(encoded_label_groups[feature_index])\n",
    "    feature_label_indices = range(label_group_starting_index, label_group_starting_index+num_group_labels, 1)\n",
    "    print(\"# categorical_features: %d\\n# encoded_label_groups: %d\"\n",
    "        % (len(categorical_features), len(encoded_label_groups)))\n",
    "    print(\"(feature_index, feature, label_group_starting_index, # group labels): (%d, %s, %d, %d)\"\n",
    "        % (feature_index, feature, label_group_starting_index, num_group_labels))\n",
    "    print(df[feature][0:10])\n",
    "    for ii in feature_label_indices:\n",
    "        print(one_hot_cols[ii][0:10])\n",
    "\n",
    "def one_hot_encode(df, features_and_encoded_labels):\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding on already-encoded data to\n",
    "    transform each feature label into its own column. This\n",
    "    helps prevent categorical variable integer mappings\n",
    "    from indirectly influencing models/fits.\n",
    "    Assumptions:\n",
    "    1. The categorical features of the input DataFrame df \n",
    "    are already encoded.\n",
    "    \"\"\"\n",
    "    # Gather the already-encoded data.\n",
    "    categorical_features = [pair[0] for pair in features_and_encoded_labels]\n",
    "    categorical_values = [df[label].tolist() for label in categorical_features]\n",
    "    categorical_matrix_transpose = np.array(categorical_values).T.tolist()\n",
    "    \n",
    "    # One-hot encode it.\n",
    "    one_hot_encoder = OneHotEncoder(dtype=int, sparse=False)\n",
    "    one_hot_encoder.fit(categorical_matrix_transpose)\n",
    "    print(\"One-hot encoding %d unique categorical features and %d unique categorical labels\"\n",
    "        % (len(one_hot_encoder.n_values_), sum(one_hot_encoder.n_values_)))\n",
    "    one_hot_cols = one_hot_encoder.transform(categorical_matrix_transpose).T.tolist()\n",
    "    \n",
    "    # Test the encoding.\n",
    "    if (False):\n",
    "        dummy_test_index = 0\n",
    "        test_one_hot_encoding(df, features_and_encoded_labels, one_hot_cols, dummy_test_index)\n",
    "    \n",
    "    # Remove the original categorical columns and \n",
    "    # add the new one_hot_cols to DataFrame.\n",
    "    df.drop(categorical_features, axis='columns', inplace=True)\n",
    "    for index, item in enumerate(features_and_encoded_labels):\n",
    "        feature = item[0]\n",
    "        labels = item[1]\n",
    "        for label in labels:\n",
    "            df[feature + \":\" + label] = one_hot_cols[index]\n",
    "            \n",
    "    return one_hot_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preview the passenger training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data dimensions:  891 rows,  11 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(TRAINING_DATA_PATH, \"PassengerId\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and process the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
